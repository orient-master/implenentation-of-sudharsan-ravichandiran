{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing RNNs\n",
    "RNNs are widely applied for use cases that involve sequential data, such as time series, text, audio, speech, video, weather, and much more. They have been greatly used in various natural language processing (NLP) tasks, such as language translation, sentiment analysis, text generation, and so on.\n",
    "\n",
    "\n",
    "RNN predict output not only based on the current input, but also on the previous hidden state. The previous hidden state acts like a memory and it captures the context of the sentence. With this context and the current input, we can predict the relevant word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward propagation in RNNs\n",
    "RNN uses forward propagation to predict the output.\n",
    "The preceding figure illustrates the following:\n",
    "- U represents the input to hidden layer weight matrix\n",
    "- W represents the hidden to hidden layer weight matrix\n",
    "- V  represents the hidden to output layer weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YHat:\n",
      "[[0.19492279 0.17353514 0.24459266 0.22929532 0.15765409]\n",
      " [0.18572061 0.20539911 0.23331536 0.19244974 0.18311518]\n",
      " [0.18770727 0.22029994 0.18444062 0.1854183  0.22213388]\n",
      " [0.22157655 0.17218015 0.20865046 0.19869341 0.19889944]\n",
      " [0.21493007 0.17450505 0.16965643 0.22768529 0.21322315]\n",
      " [0.19471596 0.21251485 0.18431497 0.18976308 0.21869113]\n",
      " [0.20252165 0.1868734  0.21659048 0.19427322 0.19974125]\n",
      " [0.19762553 0.1972614  0.17389066 0.24166912 0.18955328]\n",
      " [0.20753333 0.18808519 0.20747291 0.22186451 0.17504406]\n",
      " [0.18206537 0.21122042 0.20856465 0.18841831 0.20973125]\n",
      " [0.18261961 0.20889559 0.21573444 0.1830653  0.20968506]\n",
      " [0.20032081 0.19680268 0.18191244 0.20213823 0.21882584]\n",
      " [0.19639334 0.21788882 0.16358175 0.2228223  0.19931379]\n",
      " [0.21227118 0.17456996 0.21061558 0.2260651  0.17647817]\n",
      " [0.19832079 0.19504612 0.21270813 0.19977715 0.19414781]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the dimensions\n",
    "input_dim = 10  # The dimension of the input\n",
    "hidden_dim = 8  # The dimension of the hidden state\n",
    "output_dim = 5  # The dimension of the output\n",
    "\n",
    "# Initialize the weights using the uniform distribution\n",
    "U = np.random.uniform(\n",
    "    -np.sqrt(1.0 / input_dim), np.sqrt(1.0 / input_dim), (hidden_dim, input_dim)\n",
    ")\n",
    "W = np.random.uniform(\n",
    "    -np.sqrt(1.0 / hidden_dim), np.sqrt(1.0 / hidden_dim), (hidden_dim, hidden_dim)\n",
    ")\n",
    "V = np.random.uniform(\n",
    "    -np.sqrt(1.0 / hidden_dim), np.sqrt(1.0 / hidden_dim), (output_dim, hidden_dim)\n",
    ")\n",
    "\n",
    "# Define a random input sequence\n",
    "x = np.random.randint(0, input_dim, size=15)  # Example input sequence of length 15\n",
    "num_time_steps = len(x)\n",
    "\n",
    "# Initialize the hidden state\n",
    "hidden_state = np.zeros((num_time_steps + 1, hidden_dim))\n",
    "hidden_state[-1] = np.zeros(hidden_dim)\n",
    "\n",
    "# Initialize the output\n",
    "YHat = np.zeros((num_time_steps, output_dim))\n",
    "\n",
    "\n",
    "# Softmax function\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z))  # Stability improvement by subtracting max\n",
    "    return exp_z / exp_z.sum(axis=0)\n",
    "\n",
    "\n",
    "# Forward pass for each time step\n",
    "for t in np.arange(num_time_steps):\n",
    "    # Compute the hidden state at time t\n",
    "    hidden_state[t] = np.tanh(U[:, x[t]] + W.dot(hidden_state[t - 1]))\n",
    "    # Compute the output at time t\n",
    "    YHat[t] = softmax(V.dot(hidden_state[t]))\n",
    "\n",
    "# Display the final output\n",
    "print(\"YHat:\")\n",
    "print(YHat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating song lyrics using RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")  # Updated logging method\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/songdata.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57650"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"artist\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "Donna Summer        191\n",
       "Gordon Lightfoot    189\n",
       "Bob Dylan           188\n",
       "George Strait       188\n",
       "Loretta Lynn        187\n",
       "Cher                187\n",
       "Alabama             187\n",
       "Reba Mcentire       187\n",
       "Chaka Khan          186\n",
       "Dean Martin         186\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"artist\"].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.65785381026438"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"artist\"].value_counts().values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \", \".join(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Look at her face, it's a wonderful face  \\nAnd it means something special to me  \\nLook at the way that she smiles when she sees me  \\nHow lucky can one fellow be?  \\n  \\nShe's just my kind of girl, she makes me feel fine  \\nWho could ever believe that she could be mine?  \\nShe's just my kind of girl, without her I'm blue  \\nAnd if she ever leaves me what could I do, what co\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:369]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "print(char_to_ix[\"s\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n"
     ]
    }
   ],
   "source": [
    "print(ix_to_char[68])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "vocabSize = 7\n",
    "char_index = 4\n",
    "print(np.eye(vocabSize)[char_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(index):\n",
    "    return np.eye(vocab_size)[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of units in the hidden layer\n",
    "hidden_size = 100\n",
    "\n",
    "# Define the length of the input and output sequence\n",
    "seq_length = 25\n",
    "\n",
    "# Define the learning rate for gradient descent\n",
    "learning_rate = 1e-1\n",
    "\n",
    "# Set the seed value\n",
    "seed_value = 42\n",
    "tf.random.set_seed(seed_value)\n",
    "random.seed(seed_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# placeholders for the input and output\n",
    "inputs = tf.compat.v1.placeholder(shape=[None, vocab_size], dtype=tf.float32, name=\"inputs\")\n",
    "targets = tf.compat.v1.placeholder(shape=[None, vocab_size], dtype=tf.float32, name=\"targets\")\n",
    "\n",
    "# the placeholder for the initial hidden state\n",
    "init_state = tf.compat.v1.placeholder(shape=[1, hidden_size], dtype=tf.float32, name=\"state\")\n",
    "\n",
    "# initializer for initializing the weights of the RNN\n",
    "initializer = tf.random_normal_initializer(stddev=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the forward propagation within a variable scope named \"RNN\"\n",
    "with tf.compat.v1.variable_scope(\"RNN\") as scope:\n",
    "    h_t = init_state  # Initialize the hidden state as the initial state\n",
    "    y_hat = []  # To store the outputs at each time step\n",
    "\n",
    "    # Iterate through each time step of the sequence\n",
    "    for t, x_t in enumerate(tf.split(inputs, seq_length, axis=0)):\n",
    "        if t > 0:\n",
    "            scope.reuse_variables()  # Reuse variables after the first time step\n",
    "\n",
    "        # Define weight matrices for input-to-hidden, hidden-to-hidden, and hidden-to-output layers\n",
    "        U = tf.compat.v1.get_variable(\"U\", [vocab_size, hidden_size], initializer=initializer)\n",
    "        W = tf.compat.v1.get_variable(\"W\", [hidden_size, hidden_size], initializer=initializer)\n",
    "        V = tf.compat.v1.get_variable(\"V\", [hidden_size, vocab_size], initializer=initializer)\n",
    "\n",
    "        # Define biases for the hidden and output layers\n",
    "        bh = tf.compat.v1.get_variable(\"bh\", [hidden_size], initializer=initializer)\n",
    "        by = tf.compat.v1.get_variable(\"by\", [vocab_size], initializer=initializer)\n",
    "\n",
    "        # Calculate the new hidden state using the input x_t and the previous hidden state h_t\n",
    "        h_t = tf.tanh(tf.matmul(x_t, U) + tf.matmul(h_t, W) + bh)\n",
    "\n",
    "        # Calculate the output y_hat_t for the current time step\n",
    "        y_hat_t = tf.matmul(h_t, V) + by\n",
    "        y_hat.append(y_hat_t)  # Append the output to the y_hat list\n",
    "\n",
    "# Apply softmax to the final output to get probabilities\n",
    "output_softmax = tf.nn.softmax(y_hat[-1])\n",
    "outputs = tf.concat(y_hat, axis=0)\n",
    "\n",
    "# Compute the cross-entropy loss between the outputs and the targets\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=outputs))\n",
    "\n",
    "# Store the final hidden state of the RNN, which can be used for predictions or further processing\n",
    "hprev = h_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining BPTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Initialize the Adam optimizer\n",
    "minimizer = tf.compat.v1.train.AdamOptimizer()\n",
    "\n",
    "# Compute the gradients of the loss with the Adam optimizer\n",
    "gradients = minimizer.compute_gradients(loss)\n",
    "\n",
    "# Set the threshold for gradient clipping\n",
    "threshold = tf.constant(5.0, name=\"grad_clipping\")\n",
    "\n",
    "# Clip the gradients that exceed the threshold and bring them within the range\n",
    "clipped_gradients = []\n",
    "for grad, var in gradients:\n",
    "    if grad is not None:  # Check if the gradient is not None\n",
    "        clipped_grad = tf.clip_by_value(grad, -threshold, threshold)\n",
    "        clipped_gradients.append((clipped_grad, var))\n",
    "\n",
    "# Apply the clipped gradients to update the model's variables\n",
    "updated_gradients = minimizer.apply_gradients(clipped_gradients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start generating songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Look at her face, it's a \""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# Initialize TensorFlow session and variables\n",
    "sess = tf.compat.v1.Session()\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "# Dataset and pointer initialization\n",
    "pointer = 0\n",
    "\n",
    "# Define input and output data\n",
    "input_sentence = data[pointer:pointer + seq_length]\n",
    "input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ook at her face, it's a w\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentence = data[pointer + 1:pointer + seq_length + 1]\n",
    "output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After 0 iterations\n",
      "\n",
      " A1dAT3!GdpJ\"3.7z 7 !XROjp][762T7Zy,UyCbz,:Hk(Woi]upLSyAL(bN1,-u0ZyZd ,PgwM)\n",
      "9gwu9H8f(V?Oti!K\"ob)ubx62)!2OD\n",
      "M'V5QU7UuneY5(C7K.B\n",
      "Z'7HxYcr\"V47dkg 5a0QbB2\n",
      "bS:\"ce\"-UHfpP\"OG!LoZfO\n",
      "J0H-bT0?\"\n",
      "b9\"j-NdRP 'JMuXYVlQ1-KGO.AwnGI8f-d5T gb8W[CnN2s1Wr\"coMxLf2NvzjRU7SbsVXl'8jXjAc()G:9O6W[]'3gXYW?p9:aZ0Qj.COtUQoqP\"vTzQ.IDSKu?R1W,[CCI R1:tldcynX4?l8Qr --KCDcI]dG'RRm3EgwglqPncXfkA1MAr6b[3(IpuYFa[mWQ(LxMY0jC0o20KFeRU4r5PdE,!XqA55AP(H5i\n",
      "LXRt?j'LONKYScrOM!6unszECIEdDW\"-NN5gXW,Z,!6xC3h9!N1OVnk,SHZHeMZBnaGtM,c:WfCImffuuY \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "After 50000 iterations\n",
      "\n",
      "  lay  \n",
      "A dan't kind  \n",
      "That 'r?  \n",
      "Mo's brusth  \n",
      "N, dn'ckee, I raid!  \n",
      "Then mao:]  \n",
      "[. rolly, \"Ren trid me, it dom takes of dean. upch arrain:]  \n",
      "You fon here is life inther me...  \n",
      "[The upin Know  \n",
      "[Hras a rrow stickers.]  \n",
      "[Brdring  \n",
      "For will  \n",
      "Your hay ser !\n",
      "\n",
      ", Meings o fruemf eving (  \n",
      "[3 need my ever.  \n",
      "[?d bes m ck prech:]  \n",
      "But meming now ride is s.  \n",
      "[Edr:]]...\n",
      ", (ky sten!  \n",
      "[Bris, if what me  \n",
      "[\"?  \n",
      "But up  \n",
      "Thry, need the,  \n",
      "Eade arrung  \n",
      "[Choruz:]  \n",
      "[Edong:]  \n",
      "[Nda:]...  \n",
      "Flebse cotho-l \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "After 100000 iterations\n",
      "\n",
      " it's see you you that he can too  \n",
      "I stind me  \n",
      "And I's trek fireed  \n",
      "Hat I no you  \n",
      "Sincido like it your heart to my  \n",
      "Wily  \n",
      "I got out on this where I want won me daym I'd naidd out  \n",
      "You're always the rrombe the choil guave you  \n",
      "I tray I don't be me dreamck Die dol you  \n",
      "I don't me  \n",
      "Chase I don't can here my drink give you  \n",
      "It's gite Move to you  \n",
      "But I have you real yiah  \n",
      "Just on the kilusbact you  \n",
      "  \n",
      "Don't want  \n",
      "I'm to I gurds laning goout go,  \n",
      "  \n",
      "Justedlessure erace truese the creal \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "After 150000 iterations\n",
      "\n",
      "  I'll wait they walken baby oh oh you coure your runnin' is  \n",
      "Batle these'll be night  \n",
      " get you, y?  \n",
      "Causerthing,  \n",
      "Our should out  \n",
      "And on you love yeah youn you peep  \n",
      "When yeah  \n",
      "  \n",
      "Coad out the dayvarony feft  \n",
      "  \n",
      "Calling  \n",
      "How my surryther you on on you  \n",
      "  \n",
      "If you coule out you stile we aray, ohbout on you was lotterst a every tcy me not oh you want the gun, I want  \n",
      "The only ongezy the pright yeah yeah I low you we phink  \n",
      "  \n",
      "  \n",
      "Everyone  \n",
      "Everyson't  \n",
      "  \n",
      "Where that's that yeah year)  \n",
      " \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "After 200000 iterations\n",
      "\n",
      " omohind for out of go  \n",
      "Can't been long you  \n",
      "If I was lovent  \n",
      "Sow  \n",
      "  \n",
      "What I will my time to hear  \n",
      " go dained just ugar till I know to fall baby bar I new  \n",
      "To be hap it you knot baby  \n",
      "Those ther gone our thiss the. can't be Sight I want a lonah  \n",
      "I one's a to go on  \n",
      "Cf in love it looked that through to like the moon a rides, nothing teach rightelond there would on the rus all tell the bying to smelied, by whowe underning don't I won't can go on strease so  \n",
      "  \n",
      "  \n",
      "I love who see by night I \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "After 250000 iterations\n",
      "\n",
      "  mantrresing,  \n",
      "Ooh, I wanna be one is love me of the time,  \n",
      "Hearten?  \n",
      "  \n",
      "You let you  \n",
      "Your lave's reaged for you, sendines away in you stay  \n",
      "And thes youn, I love the days  \n",
      "Soway  \n",
      "They can't a risourted to slow, oh, you ridala way I still oneams! me  \n",
      "Show it's listen)  \n",
      "I don't thinking  \n",
      "So love. my timon't leaving to be down.  \n",
      "How I want anyeboy anywhing you  \n",
      "The only lovin' you  \n",
      "Now  \n",
      "The gack to ren to feel you.?  \n",
      "  \n",
      "  \n",
      "  \n",
      "I've missed you, I ammeret to you.  \n",
      "When you want it tow \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "After 300000 iterations\n",
      "\n",
      "  \n",
      "Staity oohter, trying\n",
      "you time endernd all the wiJh they're thinkon timet.  \n",
      "That should don't love to be little die' sheet rounting of a dangave andier, streen scalupetimet like a hold crust to stope..  \n",
      "And they're for street life to pagfes all  \n",
      "Curfs agay it up just enough a gampeded for here, when all the care  \n",
      "The sispand to hile, awa brike you sce sowe that the sammor by lose you'vitring fortpo  \n",
      "I aldes now sight  \n",
      "Can latilidiiter ko (ow we soungan, of the vie-seer, can could an peen \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "After 350000 iterations\n",
      "\n",
      " d  \n",
      "Nobody 2thore  \n",
      "Homam  \n",
      "They done  \n",
      "And nten  \n",
      "  \n",
      "Now  \n",
      "Never listen stone  \n",
      "But I've go tonnderse ond with make tarna  \n",
      "Make was shourn  \n",
      "Rece  \n",
      "What life  \n",
      "My sail  \n",
      "  \n",
      "The vister on the knows eected in my slieverum if more flies  \n",
      "We layber  \n",
      "Innuw  \n",
      "RAoming the feimsr show movidlen be leckicl bonm the mon a fut bame  \n",
      "Man  \n",
      "Teed ong  \n",
      "Mine  \n",
      "Geand  \n",
      "Like distandse back  \n",
      "Itliad  \n",
      "  \n",
      "As lost you and world  \n",
      "Never for one fayin'  \n",
      "  \n",
      "Now dis  \n",
      "  \n",
      "Make believe you dongurf away  \n",
      "Crown  \n",
      "Tur \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "After 400000 iterations\n",
      "\n",
      " surliling and more are take amosie  \n",
      "  \n",
      "There's hard is you prayer  \n",
      "We will see And  \n",
      "Or thes all somed-on,  \n",
      "  \n",
      "I gonna you gatche an rag- caller I've hear, on out  \n",
      "Lote  \n",
      "All  \n",
      "You're trade  \n",
      "All the lavealo make to stryea's on the olby etersh  \n",
      "I'm say me  \n",
      "A hole plane  \n",
      "Every sonl  \n",
      "When I can hear't now  \n",
      "Recas of a myserue  \n",
      "All play alOnend with agicked-seater to long and hear year hunt\n",
      "\n",
      ", It in alome  \n",
      "So aroaver  \n",
      "All thing the time, like racde  \n",
      "The parching  \n",
      "  \n",
      "I'll the mind fade  \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "After 450000 iterations\n",
      "\n",
      " \n",
      "Babless and \"I  \n",
      "Or they'd so lim off that to  \n",
      "It's kirst anything vluw mapey many fatting, ret me smires  \n",
      "Someer it's new exty about uwert to Lex No esup swalking  \n",
      "I'm gaves  \n",
      "A He's to fersen me  \n",
      "Back up of my blood  \n",
      "  \n",
      "We know it's all traim in  \n",
      "Leters sook that distanthe o'chuncher  \n",
      "Cause right  \n",
      "To to and sometimeon' tonrad intack are the pishrisk they truck  \n",
      "Somewhere me man  \n",
      "When you have known't crieves  \n",
      "Untying noking are lie on the matter one mine  \n",
      "On out trows at the landl \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "After 500000 iterations\n",
      "\n",
      " d to go  \n",
      "(Can yeah like every go blood of your but more time,  \n",
      "I gives gonnow can gettic move worken only say (bives eaks we gittle dey's got me, see (Oh how town lovin' call, you have presupesueally  \n",
      "Itr feel I the and to Jesped you lough a beg to me  \n",
      "To be now and I be nog bythere  \n",
      "That fast on your brokes and You've devel's grow  \n",
      "  \n",
      "Pard will)  \n",
      "I'm for thing than you ause (y...x.Junden  \n",
      "  \n",
      "So mrive blopatient astorbin got's to me ony the kisllond  \n",
      "Listone yooh's play  \n",
      "Everying us ho \n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sample_length = 500\n",
    "\n",
    "for iteration in range(500001):\n",
    "    if pointer + seq_length+1 >= len(data) or iteration == 0:\n",
    "        hprev_val = np.zeros([1, hidden_size])\n",
    "        pointer = 0\n",
    "    \n",
    "    input_sentence = data[pointer:pointer + seq_length]\n",
    "    output_sentence = data[pointer + 1:pointer + seq_length + 1]\n",
    "\n",
    "    # Convert sentences to indices\n",
    "    input_indices = [char_to_ix[ch] for ch in input_sentence]\n",
    "    target_indices = [char_to_ix[ch] for ch in output_sentence]\n",
    "\n",
    "    # Convert indices to one-hot vectors\n",
    "    input_vector = one_hot_encoder(input_indices)\n",
    "    target_vector = one_hot_encoder(target_indices)\n",
    "        \n",
    "    hprev_val, loss_val, _ = sess.run(\n",
    "        [hprev, loss, updated_gradients],\n",
    "        feed_dict={\n",
    "            inputs: input_vector,\n",
    "            targets: target_vector,\n",
    "            init_state: hprev_val\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Generate song lyrics every 50,000 iterations\n",
    "    if iteration % 50000 == 0:\n",
    "        random_index = random.randint(0, len(data) - seq_length)\n",
    "        sample_input_sent = data[random_index:random_index + seq_length]\n",
    "        sample_input_indices = [char_to_ix[ch] for ch in sample_input_sent]\n",
    "        sample_prev_state_val = np.copy(hprev_val)\n",
    "        predicted_indices = []\n",
    "\n",
    "        for t in range(sample_length):\n",
    "            sample_input_vector = one_hot_encoder(sample_input_indices)\n",
    "            probs_dist, sample_prev_state_val = sess.run(\n",
    "                [output_softmax, hprev],\n",
    "                feed_dict={\n",
    "                    inputs: sample_input_vector,\n",
    "                    init_state: sample_prev_state_val\n",
    "                }\n",
    "            )\n",
    "\n",
    "            ix = np.random.choice(range(len(char_to_ix)), p=probs_dist.ravel())\n",
    "            sample_input_indices = sample_input_indices[1:] + [ix]\n",
    "            predicted_indices.append(ix)\n",
    "\n",
    "        predicted_chars = [ix_to_char[ix] for ix in predicted_indices]\n",
    "        text = ''.join(predicted_chars)\n",
    "        print('\\n')\n",
    "        print(f'After {iteration} iterations')\n",
    "        print('\\n', text, '\\n')\n",
    "        print('-' * 115)\n",
    "\n",
    "    pointer += seq_length\n",
    "    iteration += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
